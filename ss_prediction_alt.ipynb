{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import Model, activations, layers, losses, optimizers, callbacks, regularizers\n",
    "from keras.layers import Dense, Convolution1D, Dropout, BatchNormalization, concatenate, TimeDistributed, Layer, Input\n",
    "import matplotlib.pyplot as plt\n",
    "from ss_functions import *\n",
    "from ss_pred_classes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, y_data = get_data('list.txt')\n",
    "x_train, y_train = x_data[101:], y_data[101:]\n",
    "fff, y_data = get_data('list.txt', encode_y=False)\n",
    "x_test, y_test = x_data[:101], y_data[:101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_data1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x_data, y_data \u001b[38;5;241m=\u001b[39m \u001b[43mget_data1\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlist.txt\u001b[39m\u001b[38;5;124m'\u001b[39m,padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m x_train2, y_train2 \u001b[38;5;241m=\u001b[39m x_data[\u001b[38;5;241m101\u001b[39m:], y_data[\u001b[38;5;241m101\u001b[39m:]\n\u001b[0;32m      3\u001b[0m fff, y_data \u001b[38;5;241m=\u001b[39m get_data1(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlist.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, encode_y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_data1' is not defined"
     ]
    }
   ],
   "source": [
    "x_data, y_data = get_data1('list.txt',padding=False)\n",
    "x_train2, y_train2 = x_data[101:], y_data[101:]\n",
    "fff, y_data = get_data1('list.txt', encode_y=False,padding=False)\n",
    "x_test2, y_test2 = x_data[:101], y_data[:101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data1, y_data1 = get_data2('list.txt')\n",
    "x_train1, x_train2 = np.array(x_data1[0][101:]), np.array(x_data1[1][101:])\n",
    "x_test1, x_test2 = np.array(x_data1[0][:101]), np.array(x_data1[1][:101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model0():\n",
    "    inputs = Input((None, 41))\n",
    "    inputs = layers.Masking()(inputs)\n",
    "    X = DeepInception_block()(inputs)\n",
    "    X = DeepInception_block()(X)\n",
    "    # X = DeepInception_block()(X)\n",
    "\n",
    "    X = Convolution1D(100, 11, activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001))(X)\n",
    "    X = TimeDistributed(Dense(512, activation='relu'))(X)\n",
    "    X = Dropout(0.4)(X)\n",
    "    X = TimeDistributed(Dense(256, activation='relu'))(X)\n",
    "    X = Dropout(0.4)(X)\n",
    "\n",
    "    Y = TimeDistributed(Dense(3, activation='softmax'))(X)\n",
    "    model = Model(inputs=inputs, outputs=Y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_17 (InputLayer)       [(None, None, 41)]        0         \n",
      "                                                                 \n",
      " deep_inception_block_29 (De  (None, None, 900)        1278692   \n",
      " epInception_block)                                              \n",
      "                                                                 \n",
      " deep_inception_block_30 (De  (None, None, 900)        2062100   \n",
      " epInception_block)                                              \n",
      "                                                                 \n",
      " conv1d_1630 (Conv1D)        (None, None, 100)         990100    \n",
      "                                                                 \n",
      " time_distributed_28 (TimeDi  (None, None, 512)        51712     \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, None, 512)         0         \n",
      "                                                                 \n",
      " time_distributed_29 (TimeDi  (None, None, 256)        131328    \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, None, 256)         0         \n",
      "                                                                 \n",
      " time_distributed_30 (TimeDi  (None, None, 3)          771       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,514,703\n",
      "Trainable params: 4,472,657\n",
      "Non-trainable params: 42,046\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model0()\n",
    "\n",
    "opt = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', # try siome: \"categorical_focal_crossentropy, adam, sparse_categorical_crossentropy\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy', 'mae', truncated_accuracy])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\vinicius\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\vinicius\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\vinicius\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\vinicius\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\vinicius\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\vinicius\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\vinicius\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\vinicius\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\vinicius\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Users\\vinicius\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (24,) and (24, 800, 3) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 23\u001b[0m\n\u001b[0;32m     18\u001b[0m lr_fun \u001b[38;5;241m=\u001b[39m callbacks\u001b[38;5;241m.\u001b[39mLearningRateScheduler(\n\u001b[0;32m     19\u001b[0m     learn_decay\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/GPU:1\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 23\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mstop_monitor_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# 3rd block - negligeable improvement\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vinicius\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileaw95b4u8.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\vinicius\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\vinicius\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\vinicius\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\vinicius\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\vinicius\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\vinicius\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\vinicius\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\vinicius\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\vinicius\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Users\\vinicius\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (24,) and (24, 800, 3) are incompatible\n"
     ]
    }
   ],
   "source": [
    "stop_monitor_loss = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=8,\n",
    "    mode='min',\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint = callbacks.ModelCheckpoint(\n",
    "    './ss_pred_model0.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "lr_fun = callbacks.LearningRateScheduler(\n",
    "    learn_decay\n",
    ")\n",
    "\n",
    "with tf.device('/GPU:1'):\n",
    "    history = model.fit(x_data, y_data,\n",
    "                        epochs=100,\n",
    "                        batch_size=24,\n",
    "                        validation_split=0.1,\n",
    "                        callbacks=[stop_monitor_loss, checkpoint])\n",
    "    \n",
    "# 3rd block - negligeable improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = keras.models.load_model('ss_pred_model0.keras', \n",
    "                                     custom_objects={\n",
    "                                         'inception_conv': inception_conv,\n",
    "                                         'InceptionNet_paper': InceptionNet_paper,\n",
    "                                         'DeepInception_block': DeepInception_block,\n",
    "                                         'truncated_accuracy': truncated_accuracy\n",
    "                                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 5s 251ms/step\n",
      "0.47987097574592147\n"
     ]
    }
   ],
   "source": [
    "ss_map = {'C': 0, 'H': 1, 'E': 2}\n",
    "from_aa = {0: 'C', 1: 'H', 2: 'E'}\n",
    "predictions_hot = test_model.predict(x_test)\n",
    "predictions = []\n",
    "for prediction in predictions_hot:\n",
    "    dssp = ''\n",
    "    for i in prediction:\n",
    "        dssp += from_aa[np.argmax(i)]\n",
    "    predictions.append(dssp)\n",
    "\n",
    "total = 0\n",
    "TP = 0\n",
    "for prediction, truth in zip(predictions, y_test):\n",
    "    for i, ss in enumerate(truth):\n",
    "        total +=1\n",
    "        if ss==prediction[i]:\n",
    "            TP+=1\n",
    "\n",
    "accuracy = TP/total\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block1 = DeepInception_block()\n",
    "block2 = DeepInception_block()\n",
    "block3 = DeepInception_block()\n",
    "\n",
    "inputs = layers.Input((800,41))\n",
    "X = block1(inputs)\n",
    "X = block2(X)\n",
    "X1 = Convolution1D(100, 11, activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001))(X)\n",
    "X1 = TimeDistributed(Dense(256, activation='relu'))(X1)\n",
    "X1 = Dropout(0.5)(X1)\n",
    "\n",
    "Y2 = TimeDistributed(Dense(3, activation='softmax'))(X1)\n",
    "X = block3(X)\n",
    "\n",
    "# input1 = layers.Input((800,21))\n",
    "# input2 = layers.Input((800,20))\n",
    "# X1 = block1(input1)\n",
    "# X2 = block2(input2)\n",
    "\n",
    "# X = layers.concatenate([X1,X2])\n",
    "# X = DeepInception_block()(X)\n",
    "\n",
    "X = Convolution1D(100, 11, activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001))(X)\n",
    "X = TimeDistributed(Dense(256, activation='relu'))(X)\n",
    "X = Dropout(0.5)(X)\n",
    "\n",
    "Y1 = TimeDistributed(Dense(3, activation='softmax'))(X)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=[Y1,Y2])\n",
    "\n",
    "opt = optimizers.Adam(learning_rate=0.005)\n",
    "model.compile(loss='categorical_crossentropy', # try siome: \"categorical_focal_crossentropy, adam, sparse_categorical_crossentropy\n",
    "              optimizer=opt,\n",
    "              metrics=[truncated_accuracy])\n",
    "\n",
    "stop_monitor_loss = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=8,\n",
    "    mode='min',\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint = callbacks.ModelCheckpoint(\n",
    "    './ss_pred_modeltest9.keras',\n",
    "    monitor='val_truncated_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input:\n",
    "1. one hot encoded sequence\n",
    "2. PSSM\n",
    "\n",
    "Model:\n",
    "1D convolutional neural network\n",
    "\n",
    "output:\n",
    "multiclass classification - dense layer with relu activaiton - 3?\n",
    "\n",
    "validation metric - accuray + model specific measures\n",
    "\n",
    "soruces:\n",
    "https://www.csbj.org/article/S2001-0370(22)00506-2/fulltext\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
