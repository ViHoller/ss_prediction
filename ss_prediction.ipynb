{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import Model, activations, layers, losses, optimizers, callbacks, regularizers\n",
    "from keras.layers import Dense, Convolution1D, Dropout, BatchNormalization, concatenate, TimeDistributed\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_aa = \"ARNDCEQGHILKMFPSTWYVX\"\n",
    "aa_onehot_dict = dict()\n",
    "for i, aa in enumerate(all_aa):\n",
    "    aa_onehot_dict[aa] = i\n",
    "    \n",
    "path = \"C:/Users/vinicius/Downloads/data/training/\"\n",
    "\n",
    "def aa_onehot_encoding(seq):\n",
    "    profile = []\n",
    "    for aa in seq:\n",
    "        encoded = np.zeros(21)\n",
    "        encoded[aa_onehot_dict[aa]] = 1\n",
    "        profile.append(encoded)\n",
    "    while len(profile) != 800: # pad to 800\n",
    "        profile.append(np.zeros(21))\n",
    "    return profile\n",
    "\n",
    "def parse_dssp(dssp_file):\n",
    "    with open(path+\"dssp/\"+dssp_file+\".dssp\", 'r') as file:\n",
    "        file.readline()\n",
    "        ss = file.readline().rstrip()\n",
    "    return ss\n",
    "\n",
    "def parse_pssm(pssm_filename):\n",
    "    profile = []\n",
    "    seq = ''\n",
    "    with open(path+\"pssm/\"+pssm_filename+\".pssm\", 'r') as pssm:\n",
    "        pssm_lines = pssm.readlines()\n",
    "        for line in pssm_lines[3:-6]:\n",
    "            line = line.rstrip().split()\n",
    "            seq += line[1]\n",
    "            profile_line = []\n",
    "            for n in line[22:-2]:\n",
    "                profile_line.append(float(n)/100)\n",
    "            profile.append(profile_line)\n",
    "    while (len(profile) != 800):\n",
    "        profile.append(np.zeros(20))\n",
    "    return profile, seq\n",
    "\n",
    "\n",
    "def parse_fasta(file):\n",
    "    pass\n",
    "\n",
    "ss_map = {'C': 0, 'H': 1, 'E': 2}\n",
    "\n",
    "def ss_onehot_encoding(ss_sequence):\n",
    "    ss_encoded = []\n",
    "    for struc in ss_sequence:\n",
    "        encoding = np.zeros(3)\n",
    "        encoding[ss_map[struc]] = 1\n",
    "        ss_encoded.append(encoding)\n",
    "    while (len(ss_encoded) != 800):\n",
    "        ss_encoded.append(np.zeros(3))\n",
    "    return ss_encoded\n",
    "\n",
    "def get_data(file, encode_y=True): \n",
    "    x = []\n",
    "    y = []\n",
    "    with open(path+file, 'r') as sample_file: # add some stuff to check?\n",
    "        for line in sample_file:\n",
    "            line = line.rstrip()\n",
    "            pssm, sequence = parse_pssm(line)\n",
    "            sequence_hot = aa_onehot_encoding(sequence)\n",
    "            features = np.concatenate((sequence_hot, pssm), axis=1)\n",
    "            x.append(features)\n",
    "\n",
    "            dssp = parse_dssp(line).replace('-','C')\n",
    "            if encode_y:\n",
    "                dssp = ss_onehot_encoding(dssp)\n",
    "            \n",
    "            y.append(dssp)\n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, y_data = get_data('list.txt')\n",
    "x_train, y_train = x_data[101:], y_data[101:]\n",
    "fff, y_data = get_data('list.txt', encode_y=False)\n",
    "x_test, y_test = x_data[:101], y_data[:101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = [1,1,1,3,3,3,3,3,5,5,5,5,5,5,5,7,7,7,7,7,7,7,7,7]\n",
    "n1 = [1,3,3,3,5,5,5,5,5,7,7,7,7,7,7,7]\n",
    "n2 = [1,3,3,5,5,5,7,7,7,7]\n",
    "class InceptionNet_naive(layers.Layer):\n",
    "    def __init__(self, num_layers=7, num_features=41):\n",
    "        super().__init__()\n",
    "        self.n_features = num_features\n",
    "        self.n_layers = num_layers\n",
    "        self.Xs=[]\n",
    "        self.layers = []\n",
    "        for i in n1:\n",
    "            layer = layers.Conv1D(self.n_features, kernel_size=i, padding='same')\n",
    "            self.layers.append(layer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        self.Xs=[]\n",
    "        X = inputs\n",
    "        for layer in self.layers:\n",
    "            self.Xs.append(layer(X))\n",
    "        X = layers.concatenate(self.Xs)\n",
    "\n",
    "        return layers.Activation('relu')(X)\n",
    "    \n",
    "inputs = layers.Input((800, 41))\n",
    "X = inputs\n",
    "for i in range(2):\n",
    "    X = InceptionNet_naive()(X)\n",
    "# X1 = InceptionNet_naive()(X)\n",
    "# X2 = InceptionNet_naive()(X)\n",
    "# X3 = InceptionNet_naive()(X)\n",
    "# X = layers.concatenate((X1,X2,X3))\n",
    "# X = layers.Activation('relu')(X)\n",
    "\n",
    "Y = layers.Dense(3, activation='softmax')(X)\n",
    "model = Model(inputs=inputs, outputs=Y)\n",
    "\n",
    "loss_fn = losses.CategoricalCrossentropy()\n",
    "opt = optimizers.RMSprop()\n",
    "model.compile(loss=loss_fn, # try siome: \"categorical_focal_crossentropy, adam, sparse_categorical_crossentropy\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "with tf.device('/GPU:1'):\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        epochs=5,\n",
    "                        batch_size=128,\n",
    "                        validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_map = {'C': 0, 'H': 1, 'E': 2}\n",
    "from_aa = {0: 'C', 1: 'H', 2: 'E'}\n",
    "predictions_hot = model.predict(x_test)\n",
    "predictions = []\n",
    "for prediction in predictions_hot:\n",
    "    dssp = ''\n",
    "    for i in prediction:\n",
    "        dssp += from_aa[np.argmax(i)]\n",
    "    predictions.append(dssp)\n",
    "total = 0\n",
    "TP = 0\n",
    "print(predictions)\n",
    "for prediction, truth in zip(predictions, y_test):\n",
    "    for pred_ss, truth_ss in zip(truth, prediction[:len(truth)]):\n",
    "        total +=1\n",
    "        if pred_ss==truth_ss:\n",
    "            TP+=1\n",
    "\n",
    "accuracy = TP/total\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class inception_conv_simple(layers.Layer):\n",
    "    def __init__(self, kernel_s, num_features=41):\n",
    "        super().__init__()\n",
    "        self.conv = layers.Conv1D(num_features, kernel_size=kernel_s, strides=1, padding='same', activation='relu')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        X = self.conv(inputs)\n",
    "        return X\n",
    "\n",
    "class InceptionNet_paper_simple(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1_1 = inception_conv_simple(1)\n",
    "        self.conv1_2 = inception_conv_simple(1)\n",
    "        self.conv1_3 = inception_conv_simple(1)\n",
    "        self.conv3_1 = inception_conv_simple(3)\n",
    "        self.conv3_2 = inception_conv_simple(3)\n",
    "        self.conv3_3 = inception_conv_simple(3)\n",
    "        self.conv3_4 = inception_conv_simple(3)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X1 = self.conv1_1(inputs)\n",
    "        X2 = self.conv3_1(self.conv1_2(inputs))\n",
    "        X3 = self.conv3_4(self.conv3_3(self.conv3_2(self.conv1_3(inputs))))\n",
    "    \n",
    "        X = layers.concatenate((X1,X2,X3))\n",
    "        return X # activation?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class inception_conv(layers.Layer):\n",
    "    def __init__(self, kernel_s, num_features=100):\n",
    "        super().__init__()\n",
    "        self.conv = Convolution1D(num_features, kernel_size=kernel_s, kernel_regularizer= regularizers.l2(0.001), strides=1, padding='same', activation='relu')\n",
    "        self.b_norm = BatchNormalization()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X = self.conv(inputs)\n",
    "        X = Dropout(0.3)(X)\n",
    "        X = self.b_norm(X)\n",
    "        return X\n",
    "\n",
    "\n",
    "class InceptionNet_paper(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1_1 = inception_conv(1)\n",
    "        self.conv1_2 = inception_conv(1)\n",
    "        self.conv1_3 = inception_conv(1)\n",
    "        self.conv3_1 = inception_conv(3)\n",
    "        self.conv3_2 = inception_conv(3)\n",
    "        self.conv3_3 = inception_conv(3)\n",
    "        self.conv3_4 = inception_conv(3)\n",
    "        self.b_norm1 = BatchNormalization()\n",
    "        self.b_norm2 = BatchNormalization()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X = self.b_norm1(inputs)\n",
    "        X1 = self.conv1_1(X)\n",
    "        X2 = self.conv3_1(self.conv1_2(X))\n",
    "        X3 = self.conv3_3(self.conv3_2(self.conv1_3(X)))\n",
    "        X3 = self.conv3_4(X3)\n",
    "        X = concatenate([X1,X2,X3])\n",
    "        X = self.b_norm2(X)\n",
    "        return X\n",
    "\n",
    "\n",
    "class DeepInception_block(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.inception1 = InceptionNet_paper()\n",
    "        self.inception2_1 = InceptionNet_paper()\n",
    "        self.inception2_2 = InceptionNet_paper()\n",
    "        self.inception3_1 = InceptionNet_paper()\n",
    "        self.inception3_2 = InceptionNet_paper()\n",
    "        self.inception3_3 = InceptionNet_paper()\n",
    "        self.inception3_4 = InceptionNet_paper()\n",
    "        self.b_norm = BatchNormalization()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        X1 = self.inception1(inputs)\n",
    "        X2 = self.inception2_2(self.inception2_1(inputs))\n",
    "        X3 = self.inception3_3(self.inception3_2(self.inception3_1(inputs)))\n",
    "        X3 = self.inception3_4(X3)\n",
    "        X = concatenate([X1,X2,X3])\n",
    "        X = self.b_norm(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input((800, 41))\n",
    "\n",
    "X = DeepInception_block()(inputs)\n",
    "X = DeepInception_block()(X)\n",
    "\n",
    "X = Convolution1D(100, 11, activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001))(X)\n",
    "X = TimeDistributed(Dense(256, activation='relu'))(X)\n",
    "X = Dropout(0.4)(X)\n",
    "Y = TimeDistributed(Dense(3, activation='softmax'))(X)\n",
    "\n",
    "\n",
    "model = Model(inputs=inputs, outputs=Y)\n",
    "opt = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', # try siome: \"categorical_focal_crossentropy, adam, sparse_categorical_crossentropy\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "stop_monitor_loss = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=8,\n",
    "    mode='min',\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint = callbacks.ModelCheckpoint(\n",
    "    'ss_pred_model.keras',\n",
    "    monitor='val_truncated_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "with tf.device('/GPU:1'):\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        epochs=40,\n",
    "                        batch_size=12,\n",
    "                        validation_split=0.1,\n",
    "                        callbacks=[stop_monitor_loss, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_map = {'C': 0, 'H': 1, 'E': 2}\n",
    "from_aa = {0: 'C', 1: 'H', 2: 'E'}\n",
    "predictions_hot = model.predict(x_test)\n",
    "predictions = []\n",
    "for prediction in predictions_hot:\n",
    "    dssp = ''\n",
    "    for i in prediction:\n",
    "        dssp += from_aa[np.argmax(i)]\n",
    "    predictions.append(dssp)\n",
    "\n",
    "total = 0\n",
    "TP = 0\n",
    "for prediction, truth in zip(predictions, y_test):\n",
    "    for i, ss in enumerate(truth):\n",
    "        total +=1\n",
    "        if ss==prediction[i]:\n",
    "            TP+=1\n",
    "\n",
    "accuracy = TP/total\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = []\n",
    "\n",
    "for i in range(200, 400, 20):\n",
    "    inputs = layers.Input((800, 41))\n",
    "    X = inputs\n",
    "    for _ in range(3):\n",
    "        X = InceptionNet_paper()(X)\n",
    "    X = inception_conv(11)(X)\n",
    "    X = layers.Dense(i, activation='relu')(X)\n",
    "    Y = layers.Dense(3, activation='softmax')(X)\n",
    "\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=Y)\n",
    "    model.compile(loss='categorical_crossentropy', # try siome: \"categorical_focal_crossentropy, adam, sparse_categorical_crossentropy\n",
    "                optimizer=\"sgd\",\n",
    "                metrics=['accuracy'])\n",
    "    with tf.device('/GPU:1'):\n",
    "        history = model.fit(x_train, y_train,\n",
    "                            epochs=5,\n",
    "                            batch_size=128,\n",
    "                            validation_split=0.1)\n",
    "        histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(10, 400, 10), [his.history['accuracy'][-1] for his in histories])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input:\n",
    "1. one hot encoded sequence\n",
    "2. PSSM\n",
    "\n",
    "Model:\n",
    "1D convolutional neural network\n",
    "\n",
    "output:\n",
    "multiclass classification - dense layer with relu activaiton - 3?\n",
    "\n",
    "validation metric - accuray + model specific measures\n",
    "\n",
    "soruces:\n",
    "https://www.csbj.org/article/S2001-0370(22)00506-2/fulltext\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
