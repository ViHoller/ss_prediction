{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import Model, activations, layers, losses, optimizers, callbacks, regularizers\n",
    "from keras.layers import Dense, Convolution1D, Dropout, BatchNormalization, concatenate, TimeDistributed, Layer, Input\n",
    "import matplotlib.pyplot as plt\n",
    "from ss_functions import *\n",
    "from ss_pred_classes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, y_data = get_data('list.txt')\n",
    "x_train, y_train = x_data[101:], y_data[101:]\n",
    "fff, y_data = get_data('list.txt', encode_y=False)\n",
    "x_test, y_test = x_data[:101], y_data[:101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, y_data = get_data1('list.txt',padding=False)\n",
    "x_train3, y_train3 = x_data[101:], y_data[101:]\n",
    "fff, y_data = get_data1('list.txt', encode_y=False,padding=False)\n",
    "x_test2, y_test2 = x_data[:101], y_data[:101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data1, y_data1 = get_data2('list.txt')\n",
    "x_train1, x_train2 = np.array(x_data1[0][101:]), np.array(x_data1[1][101:])\n",
    "x_test1, x_test2 = np.array(x_data1[0][:101]), np.array(x_data1[1][:101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model0():\n",
    "    inputs = Input((None, 41))\n",
    "    X = inputs\n",
    "    # X = layers.Masking()(X)\n",
    "    X = DeepInception_block()(X)\n",
    "    X = DeepInception_block()(X)\n",
    "    # X = DeepInception_block()(X)\n",
    "\n",
    "    X = Convolution1D(100, 11, activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001))(X)\n",
    "    X = TimeDistributed(Dense(256, activation='relu'))(X)\n",
    "    X = Dropout(0.4)(X)\n",
    "\n",
    "    Y = TimeDistributed(Dense(3, activation='softmax'))(X)\n",
    "    model = Model(inputs=inputs, outputs=Y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_model0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mget_model0\u001b[49m()\n\u001b[0;32m      3\u001b[0m opt \u001b[38;5;241m=\u001b[39m optimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m# try siome: \"categorical_focal_crossentropy, adam, sparse_categorical_crossentropy\u001b[39;00m\n\u001b[0;32m      5\u001b[0m               optimizer\u001b[38;5;241m=\u001b[39mopt,\n\u001b[0;32m      6\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m, truncated_accuracy])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_model0' is not defined"
     ]
    }
   ],
   "source": [
    "model = get_model0()\n",
    "\n",
    "opt = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', # try siome: \"categorical_focal_crossentropy, adam, sparse_categorical_crossentropy\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy', 'mae', truncated_accuracy])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 2.0844 - accuracy: 0.8403 - mae: 0.3536 - truncated_accuracy: 0.4143\n",
      "Epoch 1: val_accuracy improved from -inf to 0.86390, saving model to .\\ss_pred_model0.keras\n",
      "42/42 [==============================] - 23s 544ms/step - loss: 2.0844 - accuracy: 0.8403 - mae: 0.3536 - truncated_accuracy: 0.4143 - val_loss: 1.6904 - val_accuracy: 0.8639 - val_mae: 0.3509 - val_truncated_accuracy: 0.4132\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 1.2846 - accuracy: 0.8133 - mae: 0.3506 - truncated_accuracy: 0.4239\n",
      "Epoch 2: val_accuracy did not improve from 0.86390\n",
      "42/42 [==============================] - 16s 374ms/step - loss: 1.2846 - accuracy: 0.8133 - mae: 0.3506 - truncated_accuracy: 0.4239 - val_loss: 1.0610 - val_accuracy: 0.8639 - val_mae: 0.3509 - val_truncated_accuracy: 0.4132\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.7895 - accuracy: 0.9032 - mae: 0.3394 - truncated_accuracy: 0.5785\n",
      "Epoch 3: val_accuracy did not improve from 0.86390\n",
      "42/42 [==============================] - 15s 367ms/step - loss: 0.7895 - accuracy: 0.9032 - mae: 0.3394 - truncated_accuracy: 0.5785 - val_loss: 0.7038 - val_accuracy: 0.8639 - val_mae: 0.3503 - val_truncated_accuracy: 0.4132\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.5064 - accuracy: 0.9140 - mae: 0.3270 - truncated_accuracy: 0.6603\n",
      "Epoch 4: val_accuracy did not improve from 0.86390\n",
      "42/42 [==============================] - 15s 366ms/step - loss: 0.5064 - accuracy: 0.9140 - mae: 0.3270 - truncated_accuracy: 0.6603 - val_loss: 0.5404 - val_accuracy: 0.8639 - val_mae: 0.3504 - val_truncated_accuracy: 0.4132\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.3572 - accuracy: 0.9271 - mae: 0.3242 - truncated_accuracy: 0.6832\n",
      "Epoch 5: val_accuracy did not improve from 0.86390\n",
      "42/42 [==============================] - 15s 368ms/step - loss: 0.3572 - accuracy: 0.9271 - mae: 0.3242 - truncated_accuracy: 0.6832 - val_loss: 0.4445 - val_accuracy: 0.8639 - val_mae: 0.3507 - val_truncated_accuracy: 0.4132\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2701 - accuracy: 0.9371 - mae: 0.3211 - truncated_accuracy: 0.6994\n",
      "Epoch 6: val_accuracy did not improve from 0.86390\n",
      "42/42 [==============================] - 15s 360ms/step - loss: 0.2701 - accuracy: 0.9371 - mae: 0.3211 - truncated_accuracy: 0.6994 - val_loss: 0.3852 - val_accuracy: 0.8639 - val_mae: 0.3503 - val_truncated_accuracy: 0.4132\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.2224 - accuracy: 0.9338 - mae: 0.3190 - truncated_accuracy: 0.7164\n",
      "Epoch 7: val_accuracy did not improve from 0.86390\n",
      "42/42 [==============================] - 15s 362ms/step - loss: 0.2224 - accuracy: 0.9338 - mae: 0.3190 - truncated_accuracy: 0.7164 - val_loss: 0.3499 - val_accuracy: 0.8639 - val_mae: 0.3489 - val_truncated_accuracy: 0.4132\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1914 - accuracy: 0.9346 - mae: 0.3166 - truncated_accuracy: 0.7291\n",
      "Epoch 8: val_accuracy did not improve from 0.86390\n",
      "42/42 [==============================] - 16s 370ms/step - loss: 0.1914 - accuracy: 0.9346 - mae: 0.3166 - truncated_accuracy: 0.7291 - val_loss: 0.3204 - val_accuracy: 0.8639 - val_mae: 0.3469 - val_truncated_accuracy: 0.4132\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1744 - accuracy: 0.9374 - mae: 0.3154 - truncated_accuracy: 0.7354\n",
      "Epoch 9: val_accuracy improved from 0.86390 to 0.87991, saving model to .\\ss_pred_model0.keras\n",
      "42/42 [==============================] - 16s 394ms/step - loss: 0.1744 - accuracy: 0.9374 - mae: 0.3154 - truncated_accuracy: 0.7354 - val_loss: 0.2549 - val_accuracy: 0.8799 - val_mae: 0.3399 - val_truncated_accuracy: 0.4864\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1628 - accuracy: 0.9260 - mae: 0.3141 - truncated_accuracy: 0.7417\n",
      "Epoch 10: val_accuracy improved from 0.87991 to 0.89930, saving model to .\\ss_pred_model0.keras\n",
      "42/42 [==============================] - 16s 387ms/step - loss: 0.1628 - accuracy: 0.9260 - mae: 0.3141 - truncated_accuracy: 0.7417 - val_loss: 0.2284 - val_accuracy: 0.8993 - val_mae: 0.3377 - val_truncated_accuracy: 0.5697\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1591 - accuracy: 0.9415 - mae: 0.3148 - truncated_accuracy: 0.7421\n",
      "Epoch 11: val_accuracy improved from 0.89930 to 0.93257, saving model to .\\ss_pred_model0.keras\n",
      "42/42 [==============================] - 16s 388ms/step - loss: 0.1591 - accuracy: 0.9415 - mae: 0.3148 - truncated_accuracy: 0.7421 - val_loss: 0.1970 - val_accuracy: 0.9326 - val_mae: 0.3290 - val_truncated_accuracy: 0.7131\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1510 - accuracy: 0.9358 - mae: 0.3129 - truncated_accuracy: 0.7507\n",
      "Epoch 12: val_accuracy improved from 0.93257 to 0.94084, saving model to .\\ss_pred_model0.keras\n",
      "42/42 [==============================] - 17s 397ms/step - loss: 0.1510 - accuracy: 0.9358 - mae: 0.3129 - truncated_accuracy: 0.7507 - val_loss: 0.1780 - val_accuracy: 0.9408 - val_mae: 0.3226 - val_truncated_accuracy: 0.7454\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1479 - accuracy: 0.9344 - mae: 0.3130 - truncated_accuracy: 0.7492\n",
      "Epoch 13: val_accuracy did not improve from 0.94084\n",
      "42/42 [==============================] - 15s 364ms/step - loss: 0.1479 - accuracy: 0.9344 - mae: 0.3130 - truncated_accuracy: 0.7492 - val_loss: 0.1695 - val_accuracy: 0.9398 - val_mae: 0.3182 - val_truncated_accuracy: 0.7370\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1442 - accuracy: 0.9453 - mae: 0.3124 - truncated_accuracy: 0.7557\n",
      "Epoch 14: val_accuracy improved from 0.94084 to 0.94740, saving model to .\\ss_pred_model0.keras\n",
      "42/42 [==============================] - 16s 375ms/step - loss: 0.1442 - accuracy: 0.9453 - mae: 0.3124 - truncated_accuracy: 0.7557 - val_loss: 0.1575 - val_accuracy: 0.9474 - val_mae: 0.3143 - val_truncated_accuracy: 0.7709\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1464 - accuracy: 0.9377 - mae: 0.3128 - truncated_accuracy: 0.7522\n",
      "Epoch 15: val_accuracy did not improve from 0.94740\n",
      "42/42 [==============================] - 15s 349ms/step - loss: 0.1464 - accuracy: 0.9377 - mae: 0.3128 - truncated_accuracy: 0.7522 - val_loss: 0.1896 - val_accuracy: 0.9367 - val_mae: 0.3205 - val_truncated_accuracy: 0.7210\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1509 - accuracy: 0.9457 - mae: 0.3122 - truncated_accuracy: 0.7539\n",
      "Epoch 16: val_accuracy improved from 0.94740 to 0.95025, saving model to .\\ss_pred_model0.keras\n",
      "42/42 [==============================] - 16s 371ms/step - loss: 0.1509 - accuracy: 0.9457 - mae: 0.3122 - truncated_accuracy: 0.7539 - val_loss: 0.1536 - val_accuracy: 0.9503 - val_mae: 0.3100 - val_truncated_accuracy: 0.7882\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1448 - accuracy: 0.9494 - mae: 0.3114 - truncated_accuracy: 0.7597\n",
      "Epoch 17: val_accuracy did not improve from 0.95025\n",
      "42/42 [==============================] - 14s 329ms/step - loss: 0.1448 - accuracy: 0.9494 - mae: 0.3114 - truncated_accuracy: 0.7597 - val_loss: 0.1557 - val_accuracy: 0.9474 - val_mae: 0.3096 - val_truncated_accuracy: 0.7732\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1432 - accuracy: 0.9501 - mae: 0.3115 - truncated_accuracy: 0.7605\n",
      "Epoch 18: val_accuracy improved from 0.95025 to 0.95289, saving model to .\\ss_pred_model0.keras\n",
      "42/42 [==============================] - 15s 366ms/step - loss: 0.1432 - accuracy: 0.9501 - mae: 0.3115 - truncated_accuracy: 0.7605 - val_loss: 0.1416 - val_accuracy: 0.9529 - val_mae: 0.3058 - val_truncated_accuracy: 0.7970\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1418 - accuracy: 0.9494 - mae: 0.3115 - truncated_accuracy: 0.7585\n",
      "Epoch 19: val_accuracy did not improve from 0.95289\n",
      "42/42 [==============================] - 14s 336ms/step - loss: 0.1418 - accuracy: 0.9494 - mae: 0.3115 - truncated_accuracy: 0.7585 - val_loss: 0.1517 - val_accuracy: 0.9461 - val_mae: 0.3070 - val_truncated_accuracy: 0.7661\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1416 - accuracy: 0.9445 - mae: 0.3111 - truncated_accuracy: 0.7601\n",
      "Epoch 20: val_accuracy did not improve from 0.95289\n",
      "42/42 [==============================] - 14s 330ms/step - loss: 0.1416 - accuracy: 0.9445 - mae: 0.3111 - truncated_accuracy: 0.7601 - val_loss: 0.1499 - val_accuracy: 0.9485 - val_mae: 0.3083 - val_truncated_accuracy: 0.7785\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1407 - accuracy: 0.9495 - mae: 0.3110 - truncated_accuracy: 0.7612\n",
      "Epoch 21: val_accuracy did not improve from 0.95289\n",
      "42/42 [==============================] - 14s 333ms/step - loss: 0.1407 - accuracy: 0.9495 - mae: 0.3110 - truncated_accuracy: 0.7612 - val_loss: 0.1425 - val_accuracy: 0.9504 - val_mae: 0.3028 - val_truncated_accuracy: 0.7852\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1387 - accuracy: 0.9505 - mae: 0.3108 - truncated_accuracy: 0.7621\n",
      "Epoch 22: val_accuracy improved from 0.95289 to 0.95291, saving model to .\\ss_pred_model0.keras\n",
      "42/42 [==============================] - 16s 387ms/step - loss: 0.1387 - accuracy: 0.9505 - mae: 0.3108 - truncated_accuracy: 0.7621 - val_loss: 0.1378 - val_accuracy: 0.9529 - val_mae: 0.3038 - val_truncated_accuracy: 0.7959\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1408 - accuracy: 0.9484 - mae: 0.3117 - truncated_accuracy: 0.7588\n",
      "Epoch 23: val_accuracy did not improve from 0.95291\n",
      "42/42 [==============================] - 14s 335ms/step - loss: 0.1408 - accuracy: 0.9484 - mae: 0.3117 - truncated_accuracy: 0.7588 - val_loss: 0.1460 - val_accuracy: 0.9495 - val_mae: 0.3017 - val_truncated_accuracy: 0.7808\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1414 - accuracy: 0.9510 - mae: 0.3105 - truncated_accuracy: 0.7658\n",
      "Epoch 24: val_accuracy did not improve from 0.95291\n",
      "42/42 [==============================] - 14s 344ms/step - loss: 0.1414 - accuracy: 0.9510 - mae: 0.3105 - truncated_accuracy: 0.7658 - val_loss: 0.1452 - val_accuracy: 0.9449 - val_mae: 0.3059 - val_truncated_accuracy: 0.7915\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1438 - accuracy: 0.9452 - mae: 0.3116 - truncated_accuracy: 0.7588\n",
      "Epoch 25: val_accuracy did not improve from 0.95291\n",
      "42/42 [==============================] - 14s 342ms/step - loss: 0.1438 - accuracy: 0.9452 - mae: 0.3116 - truncated_accuracy: 0.7588 - val_loss: 0.1402 - val_accuracy: 0.9516 - val_mae: 0.3014 - val_truncated_accuracy: 0.7917\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1391 - accuracy: 0.9434 - mae: 0.3104 - truncated_accuracy: 0.7607\n",
      "Epoch 26: val_accuracy did not improve from 0.95291\n",
      "42/42 [==============================] - 14s 337ms/step - loss: 0.1391 - accuracy: 0.9434 - mae: 0.3104 - truncated_accuracy: 0.7607 - val_loss: 0.1438 - val_accuracy: 0.9492 - val_mae: 0.3051 - val_truncated_accuracy: 0.7816\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1393 - accuracy: 0.9462 - mae: 0.3112 - truncated_accuracy: 0.7628\n",
      "Epoch 27: val_accuracy did not improve from 0.95291\n",
      "42/42 [==============================] - 14s 332ms/step - loss: 0.1393 - accuracy: 0.9462 - mae: 0.3112 - truncated_accuracy: 0.7628 - val_loss: 0.1440 - val_accuracy: 0.9501 - val_mae: 0.3056 - val_truncated_accuracy: 0.7873\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1376 - accuracy: 0.9500 - mae: 0.3106 - truncated_accuracy: 0.7635\n",
      "Epoch 28: val_accuracy did not improve from 0.95291\n",
      "42/42 [==============================] - 14s 333ms/step - loss: 0.1376 - accuracy: 0.9500 - mae: 0.3106 - truncated_accuracy: 0.7635 - val_loss: 0.1438 - val_accuracy: 0.9506 - val_mae: 0.3058 - val_truncated_accuracy: 0.7853\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1373 - accuracy: 0.9515 - mae: 0.3102 - truncated_accuracy: 0.7663\n",
      "Epoch 29: val_accuracy did not improve from 0.95291\n",
      "42/42 [==============================] - 14s 338ms/step - loss: 0.1373 - accuracy: 0.9515 - mae: 0.3102 - truncated_accuracy: 0.7663 - val_loss: 0.1370 - val_accuracy: 0.9523 - val_mae: 0.3031 - val_truncated_accuracy: 0.7944\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1385 - accuracy: 0.9477 - mae: 0.3110 - truncated_accuracy: 0.7619\n",
      "Epoch 30: val_accuracy did not improve from 0.95291\n",
      "42/42 [==============================] - 15s 345ms/step - loss: 0.1385 - accuracy: 0.9477 - mae: 0.3110 - truncated_accuracy: 0.7619 - val_loss: 0.1647 - val_accuracy: 0.9421 - val_mae: 0.3042 - val_truncated_accuracy: 0.7469\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1371 - accuracy: 0.9504 - mae: 0.3104 - truncated_accuracy: 0.7623\n",
      "Epoch 31: val_accuracy did not improve from 0.95291\n",
      "42/42 [==============================] - 14s 329ms/step - loss: 0.1371 - accuracy: 0.9504 - mae: 0.3104 - truncated_accuracy: 0.7623 - val_loss: 0.1370 - val_accuracy: 0.9513 - val_mae: 0.3011 - val_truncated_accuracy: 0.7913\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1393 - accuracy: 0.9497 - mae: 0.3110 - truncated_accuracy: 0.7602\n",
      "Epoch 32: val_accuracy did not improve from 0.95291\n",
      "42/42 [==============================] - 14s 345ms/step - loss: 0.1393 - accuracy: 0.9497 - mae: 0.3110 - truncated_accuracy: 0.7602 - val_loss: 0.1442 - val_accuracy: 0.9500 - val_mae: 0.3042 - val_truncated_accuracy: 0.7808\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1421 - accuracy: 0.9500 - mae: 0.3119 - truncated_accuracy: 0.7564\n",
      "Epoch 33: val_accuracy did not improve from 0.95291\n",
      "42/42 [==============================] - 14s 329ms/step - loss: 0.1421 - accuracy: 0.9500 - mae: 0.3119 - truncated_accuracy: 0.7564 - val_loss: 0.3097 - val_accuracy: 0.9329 - val_mae: 0.3079 - val_truncated_accuracy: 0.7068\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1397 - accuracy: 0.9496 - mae: 0.3108 - truncated_accuracy: 0.7615\n",
      "Epoch 34: val_accuracy did not improve from 0.95291\n",
      "42/42 [==============================] - 14s 341ms/step - loss: 0.1397 - accuracy: 0.9496 - mae: 0.3108 - truncated_accuracy: 0.7615 - val_loss: 0.1609 - val_accuracy: 0.9353 - val_mae: 0.3065 - val_truncated_accuracy: 0.7471\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1379 - accuracy: 0.9516 - mae: 0.3101 - truncated_accuracy: 0.7662\n",
      "Epoch 35: val_accuracy improved from 0.95291 to 0.95341, saving model to .\\ss_pred_model0.keras\n",
      "42/42 [==============================] - 16s 390ms/step - loss: 0.1379 - accuracy: 0.9516 - mae: 0.3101 - truncated_accuracy: 0.7662 - val_loss: 0.1359 - val_accuracy: 0.9534 - val_mae: 0.3024 - val_truncated_accuracy: 0.8014\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1399 - accuracy: 0.9512 - mae: 0.3106 - truncated_accuracy: 0.7641\n",
      "Epoch 36: val_accuracy did not improve from 0.95341\n",
      "42/42 [==============================] - 14s 340ms/step - loss: 0.1399 - accuracy: 0.9512 - mae: 0.3106 - truncated_accuracy: 0.7641 - val_loss: 0.1431 - val_accuracy: 0.9515 - val_mae: 0.3064 - val_truncated_accuracy: 0.7923\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1356 - accuracy: 0.9523 - mae: 0.3100 - truncated_accuracy: 0.7680\n",
      "Epoch 37: val_accuracy did not improve from 0.95341\n",
      "42/42 [==============================] - 14s 337ms/step - loss: 0.1356 - accuracy: 0.9523 - mae: 0.3100 - truncated_accuracy: 0.7680 - val_loss: 0.1341 - val_accuracy: 0.9529 - val_mae: 0.3019 - val_truncated_accuracy: 0.7980\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1384 - accuracy: 0.9491 - mae: 0.3109 - truncated_accuracy: 0.7606\n",
      "Epoch 38: val_accuracy did not improve from 0.95341\n",
      "42/42 [==============================] - 14s 332ms/step - loss: 0.1384 - accuracy: 0.9491 - mae: 0.3109 - truncated_accuracy: 0.7606 - val_loss: 0.1394 - val_accuracy: 0.9509 - val_mae: 0.3030 - val_truncated_accuracy: 0.7897\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1361 - accuracy: 0.9519 - mae: 0.3101 - truncated_accuracy: 0.7672\n",
      "Epoch 39: val_accuracy did not improve from 0.95341\n",
      "42/42 [==============================] - 14s 332ms/step - loss: 0.1361 - accuracy: 0.9519 - mae: 0.3101 - truncated_accuracy: 0.7672 - val_loss: 0.1378 - val_accuracy: 0.9515 - val_mae: 0.3007 - val_truncated_accuracy: 0.7903\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1359 - accuracy: 0.9517 - mae: 0.3099 - truncated_accuracy: 0.7637\n",
      "Epoch 40: val_accuracy did not improve from 0.95341\n",
      "42/42 [==============================] - 14s 342ms/step - loss: 0.1359 - accuracy: 0.9517 - mae: 0.3099 - truncated_accuracy: 0.7637 - val_loss: 0.1417 - val_accuracy: 0.9494 - val_mae: 0.3050 - val_truncated_accuracy: 0.7836\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1369 - accuracy: 0.9508 - mae: 0.3107 - truncated_accuracy: 0.7614\n",
      "Epoch 41: val_accuracy did not improve from 0.95341\n",
      "42/42 [==============================] - 14s 337ms/step - loss: 0.1369 - accuracy: 0.9508 - mae: 0.3107 - truncated_accuracy: 0.7614 - val_loss: 0.1388 - val_accuracy: 0.9521 - val_mae: 0.3039 - val_truncated_accuracy: 0.7947\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1353 - accuracy: 0.9523 - mae: 0.3101 - truncated_accuracy: 0.7692\n",
      "Epoch 42: val_accuracy did not improve from 0.95341\n",
      "42/42 [==============================] - 14s 335ms/step - loss: 0.1353 - accuracy: 0.9523 - mae: 0.3101 - truncated_accuracy: 0.7692 - val_loss: 0.1413 - val_accuracy: 0.9512 - val_mae: 0.3036 - val_truncated_accuracy: 0.7903\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1362 - accuracy: 0.9516 - mae: 0.3099 - truncated_accuracy: 0.7636\n",
      "Epoch 43: val_accuracy did not improve from 0.95341\n",
      "42/42 [==============================] - 15s 356ms/step - loss: 0.1362 - accuracy: 0.9516 - mae: 0.3099 - truncated_accuracy: 0.7636 - val_loss: 0.1385 - val_accuracy: 0.9516 - val_mae: 0.3036 - val_truncated_accuracy: 0.7919\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1365 - accuracy: 0.9506 - mae: 0.3100 - truncated_accuracy: 0.7648\n",
      "Epoch 44: val_accuracy did not improve from 0.95341\n",
      "42/42 [==============================] - 14s 343ms/step - loss: 0.1365 - accuracy: 0.9506 - mae: 0.3100 - truncated_accuracy: 0.7648 - val_loss: 0.1416 - val_accuracy: 0.9505 - val_mae: 0.3030 - val_truncated_accuracy: 0.7836\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 0.1376 - accuracy: 0.9520 - mae: 0.3101 - truncated_accuracy: 0.7665Restoring model weights from the end of the best epoch: 37.\n",
      "\n",
      "Epoch 45: val_accuracy did not improve from 0.95341\n",
      "42/42 [==============================] - 15s 352ms/step - loss: 0.1376 - accuracy: 0.9520 - mae: 0.3101 - truncated_accuracy: 0.7665 - val_loss: 0.1434 - val_accuracy: 0.9503 - val_mae: 0.3034 - val_truncated_accuracy: 0.7842\n",
      "Epoch 45: early stopping\n"
     ]
    }
   ],
   "source": [
    "stop_monitor_loss = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=8,\n",
    "    mode='min',\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint = callbacks.ModelCheckpoint(\n",
    "    './ss_pred_model0.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "lr_fun = callbacks.LearningRateScheduler(\n",
    "    learn_decay\n",
    ")\n",
    "\n",
    "with tf.device('/GPU:1'):\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        epochs=100,\n",
    "                        batch_size=24,\n",
    "                        validation_split=0.1,\n",
    "                        callbacks=[stop_monitor_loss, checkpoint])\n",
    "    \n",
    "# 3rd block - negligeable improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = keras.models.load_model('ss_pred_model0.keras', \n",
    "                                     custom_objects={\n",
    "                                         'inception_conv': inception_conv,\n",
    "                                         'InceptionNet_paper': InceptionNet_paper,\n",
    "                                         'DeepInception_block': DeepInception_block,\n",
    "                                         'truncated_accuracy': truncated_accuracy\n",
    "                                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 5s 251ms/step\n",
      "0.47987097574592147\n"
     ]
    }
   ],
   "source": [
    "ss_map = {'C': 0, 'H': 1, 'E': 2}\n",
    "from_aa = {0: 'C', 1: 'H', 2: 'E'}\n",
    "predictions_hot = test_model.predict(x_test)\n",
    "predictions = []\n",
    "for prediction in predictions_hot:\n",
    "    dssp = ''\n",
    "    for i in prediction:\n",
    "        dssp += from_aa[np.argmax(i)]\n",
    "    predictions.append(dssp)\n",
    "\n",
    "total = 0\n",
    "TP = 0\n",
    "for prediction, truth in zip(predictions, y_test):\n",
    "    for i, ss in enumerate(truth):\n",
    "        total +=1\n",
    "        if ss==prediction[i]:\n",
    "            TP+=1\n",
    "\n",
    "accuracy = TP/total\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block1 = DeepInception_block()\n",
    "block2 = DeepInception_block()\n",
    "block3 = DeepInception_block()\n",
    "\n",
    "inputs = layers.Input((800,41))\n",
    "X = block1(inputs)\n",
    "X = block2(X)\n",
    "X1 = Convolution1D(100, 11, activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001))(X)\n",
    "X1 = TimeDistributed(Dense(256, activation='relu'))(X1)\n",
    "X1 = Dropout(0.5)(X1)\n",
    "\n",
    "Y2 = TimeDistributed(Dense(3, activation='softmax'))(X1)\n",
    "X = block3(X)\n",
    "\n",
    "# input1 = layers.Input((800,21))\n",
    "# input2 = layers.Input((800,20))\n",
    "# X1 = block1(input1)\n",
    "# X2 = block2(input2)\n",
    "\n",
    "# X = layers.concatenate([X1,X2])\n",
    "# X = DeepInception_block()(X)\n",
    "\n",
    "X = Convolution1D(100, 11, activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.001))(X)\n",
    "X = TimeDistributed(Dense(256, activation='relu'))(X)\n",
    "X = Dropout(0.5)(X)\n",
    "\n",
    "Y1 = TimeDistributed(Dense(3, activation='softmax'))(X)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=[Y1,Y2])\n",
    "\n",
    "opt = optimizers.Adam(learning_rate=0.005)\n",
    "model.compile(loss='categorical_crossentropy', # try siome: \"categorical_focal_crossentropy, adam, sparse_categorical_crossentropy\n",
    "              optimizer=opt,\n",
    "              metrics=[truncated_accuracy])\n",
    "\n",
    "stop_monitor_loss = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=8,\n",
    "    mode='min',\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint = callbacks.ModelCheckpoint(\n",
    "    './ss_pred_modeltest9.keras',\n",
    "    monitor='val_truncated_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input:\n",
    "1. one hot encoded sequence\n",
    "2. PSSM\n",
    "\n",
    "Model:\n",
    "1D convolutional neural network\n",
    "\n",
    "output:\n",
    "multiclass classification - dense layer with relu activaiton - 3?\n",
    "\n",
    "validation metric - accuray + model specific measures\n",
    "\n",
    "soruces:\n",
    "https://www.csbj.org/article/S2001-0370(22)00506-2/fulltext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
