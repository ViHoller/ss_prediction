{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\vinic\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import Model, layers, activations, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_aa = \"ARNDCEQGHILKMFPSTWYVX\"\n",
    "aa_onehot_dict = dict()\n",
    "for i, aa in enumerate(all_aa):\n",
    "    aa_onehot_dict[aa] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/vinic/Downloads/data/training/\"\n",
    "\n",
    "def aa_onehot_encoding(seq):\n",
    "    profile = []\n",
    "    for aa in seq:\n",
    "        encoded = np.zeros(21)\n",
    "        encoded[aa_onehot_dict[aa]] = 1\n",
    "        profile.append(encoded)\n",
    "    while len(profile) != 800: # pad to 800\n",
    "        profile.append(np.zeros(21))\n",
    "    return profile\n",
    "\n",
    "def parse_dssp(dssp_file):\n",
    "    with open(path+\"dssp/\"+dssp_file+\".dssp\", 'r') as file:\n",
    "        file.readline()\n",
    "        ss = file.readline().rstrip()\n",
    "    return ss\n",
    "\n",
    "def parse_pssm(pssm_filename):\n",
    "    profile = []\n",
    "    seq = ''\n",
    "    with open(path+\"pssm/\"+pssm_filename+\".pssm\", 'r') as pssm:\n",
    "        pssm_lines = pssm.readlines()\n",
    "        for line in pssm_lines[3:-6]:\n",
    "            line = line.rstrip().split()\n",
    "            seq += line[1]\n",
    "            profile_line = []\n",
    "            for n in line[22:-2]:\n",
    "                profile_line.append(float(n)/100)\n",
    "            profile.append(profile_line)\n",
    "    while (len(profile) != 800):\n",
    "        profile.append(np.zeros(20))\n",
    "    return profile, seq\n",
    "\n",
    "\n",
    "def parse_fasta(file):\n",
    "    pass\n",
    "\n",
    "ss_map = {'C': 0, 'H': 1, 'E': 2}\n",
    "\n",
    "def ss_onehot_encoding(ss_sequence):\n",
    "    ss_encoded = []\n",
    "    for struc in ss_sequence:\n",
    "        encoding = np.zeros(3)\n",
    "        encoding[ss_map[struc]] = 1\n",
    "        ss_encoded.append(encoding)\n",
    "    while (len(ss_encoded) != 800):\n",
    "        ss_encoded.append(np.zeros(3))\n",
    "    return ss_encoded\n",
    "\n",
    "def get_data(file, encode_y=True): \n",
    "    x = []\n",
    "    y = []\n",
    "    with open(path+file, 'r') as sample_file: # add some stuff to check?\n",
    "        for line in sample_file:\n",
    "            line = line.rstrip()\n",
    "            pssm, sequence = parse_pssm(line)\n",
    "            sequence_hot = aa_onehot_encoding(sequence)\n",
    "            features = np.concatenate((sequence_hot, pssm), axis=1)\n",
    "            x.append(features)\n",
    "\n",
    "            dssp = parse_dssp(line).replace('-','C')\n",
    "            if encode_y:\n",
    "                dssp = ss_onehot_encoding(dssp)\n",
    "            \n",
    "            y.append(dssp)\n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = get_data('cv/train1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionNet_naive(layers.Layer):\n",
    "    def __init__(self, num_features=2):\n",
    "        super().__init__()\n",
    "        self.k = num_features\n",
    "\n",
    "    def call(self, inputs, num_layers=3, layer_size=8):\n",
    "        X1 = layers.Conv2D(layer_size, kernel_size=(1), strides=1, padding='same')(inputs)\n",
    "        X2 = layers.Conv2D(layer_size, kernel_size=(3), strides=1, padding='same')(inputs)\n",
    "        X3 = layers.Conv2D(layer_size, kernel_size=(5), strides=1, padding='same')(X)\n",
    "        X = layers.concatenate((X1, X2, X3))\n",
    "\n",
    "        # X_layers = []\n",
    "        # for i in range(layers):\n",
    "        #     fs = i*2 + 1\n",
    "        #     X_layers.append(layers.conv1D(layer_size, filter=(1,fs)))\n",
    "        # X = layers.concatenate(X_layers)\n",
    "        return activations.relu(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionNet_naive_chat(layers.Layer):\n",
    "    def __init__(self, num_features=41, num_layers=7):\n",
    "        super().__init__()\n",
    "        self.k = num_features\n",
    "        self.conv_Xs = []\n",
    "        self.conv_layers = []\n",
    "        for i in range(num_layers):\n",
    "            self.conv_layers.append(layers.Conv1D(self.k, kernel_size=2*i+1, strides=1, padding='same'))\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        Xs = [conv(inputs) for conv in self.conv_layers]\n",
    "        X = layers.concatenate(Xs)\n",
    "        return layers.Activation('relu')(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionNet_naive(layers.Layer):\n",
    "    def __init__(self, num_features=41, num_layers=7):\n",
    "        super().__init__()\n",
    "        self.k = num_features\n",
    "        self.conv_Xs = []\n",
    "        self.conv1 = layers.Conv1D(self.k, kernel_size=1, strides=1, padding='same')\n",
    "        self.conv2 = layers.Conv1D(self.k, kernel_size=3, strides=1, padding='same')    \n",
    "        self.conv3 = layers.Conv1D(self.k, kernel_size=5, strides=1, padding='same')\n",
    "        self.conv4 = layers.Conv1D(self.k, kernel_size=7, strides=1, padding='same') \n",
    "        self.conv5 = layers.Conv1D(self.k, kernel_size=9, strides=1, padding='same')\n",
    "        self.conv6 = layers.Conv1D(self.k, kernel_size=11, strides=1, padding='same') \n",
    "        self.conv7 = layers.Conv1D(self.k, kernel_size=13, strides=1, padding='same') \n",
    "        self.conv_layers = [self.conv1, self.conv2, self.conv3, self.conv4, self.conv5, self.conv6, self.conv7]\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        X1 = self.conv1(inputs)\n",
    "        X2 = self.conv2(inputs)\n",
    "        X3 = self.conv3(inputs)\n",
    "        X4 = self.conv4(inputs)\n",
    "        X5 = self.conv5(inputs)\n",
    "        X6 = self.conv6(inputs) \n",
    "        X7 = self.conv7(inputs)\n",
    "        X = layers.concatenate((X1,X2,X3,X4,X5,X6,X7))\n",
    "        \n",
    "        return layers.Activation('relu')(X)\n",
    "    \n",
    "\n",
    "num_labels = 3\n",
    "num_positions = 800\n",
    "\n",
    "inputs = layers.Input((800, 41))\n",
    "X = inputs\n",
    "# X = layers.Masking(mask_value=0)(X)\n",
    "for i in range(3):\n",
    "    X = InceptionNet_naive_chat()(X)\n",
    "Y = layers.Dense(3, activation='softmax')(X)\n",
    "# Y = layers.Reshape((num_positions,num_labels))(Y)\n",
    "\n",
    "loss_fn = losses.CategoricalCrossentropy()\n",
    "\n",
    "model = Model(inputs=inputs, outputs=Y)\n",
    "model.compile(loss='categorical_crossentropy', # try siome: \"categorical_focal_crossentropy, adam, sparse_categorical_crossentropy\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7/7 [==============================] - 32s 4s/step - loss: 0.2270 - accuracy: 0.8334 - val_loss: 0.2605 - val_accuracy: 0.8171\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 37s 5s/step - loss: 0.2249 - accuracy: 0.8418 - val_loss: 0.2587 - val_accuracy: 0.8251\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 34s 5s/step - loss: 0.2233 - accuracy: 0.8500 - val_loss: 0.2572 - val_accuracy: 0.8330\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 32s 4s/step - loss: 0.2220 - accuracy: 0.8574 - val_loss: 0.2560 - val_accuracy: 0.8404\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 32s 5s/step - loss: 0.2210 - accuracy: 0.8640 - val_loss: 0.2550 - val_accuracy: 0.8464\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=5,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = get_data('cv/test1.txt', encode_y=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 4s 399ms/step\n",
      "0.378698224852071\n"
     ]
    }
   ],
   "source": [
    "ss_map = {'C': 0, 'H': 1, 'E': 2}\n",
    "from_aa = {0: 'C', 1: 'H', 2: 'E'}\n",
    "predictions_hot = model.predict(x_test)\n",
    "predictions = []\n",
    "for prediction in predictions_hot:\n",
    "    dssp = ''\n",
    "    for i in prediction:\n",
    "        dssp += from_aa[np.argmax(i)]\n",
    "    predictions.append(dssp)\n",
    "\n",
    "total = 0\n",
    "TP = 0\n",
    "for prediction, truth in zip(predictions, y_test):\n",
    "    for i, ss in enumerate(truth):\n",
    "        total +=1\n",
    "        if ss==prediction[i]:\n",
    "            TP+=1\n",
    "\n",
    "accuracy = TP/total\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input:\n",
    "1. one hot encoded sequence\n",
    "2. PSSM\n",
    "\n",
    "Model:\n",
    "1D convolutional neural network\n",
    "\n",
    "output:\n",
    "multiclass classification - dense layer with relu activaiton - 3?\n",
    "\n",
    "validation metric - accuray + model specific measures\n",
    "\n",
    "soruces:\n",
    "https://www.csbj.org/article/S2001-0370(22)00506-2/fulltext\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
